#!/usr/bin/env python3
"""
aarg - Agentenanstaltsregelgenerator (Agent Institution Rule Generator)

Generates enterprise-ready firejail profiles ("Agentenanstaltsregeln") to securely
sandbox AI coding assistants while preserving their functionality. Uses dynamic
system library discovery and respects enterprise DNS configurations for compatibility
across Linux distributions and corporate environments.

Key Features:
- Dynamic system library discovery (no hardcoded versions)
- Enterprise DNS support (respects local/corporate DNS servers)
- Cross-assistant dependency detection (e.g., Claude with Gemini MCP)
- Distribution-agnostic profiles (works on any Linux distro)
- Whitelist-only security approach (principle of least privilege)

Supports Claude Code, Gemini CLI, OpenCode, Windsurf, Cursor, and other MCP-compatible assistants.
"""

import argparse
import json
import logging
import os
import re
import shutil
import subprocess
import sys
from dataclasses import dataclass, field
from enum import Enum
from pathlib import Path
from typing import Any, Dict, List, Optional, Set, Tuple

# Configure logging with rich format
logging.basicConfig(
    level=logging.INFO,
    format='%(message)s',
    handlers=[logging.StreamHandler()]
)
logger = logging.getLogger(__name__)


class AssistantType(Enum):
    """Supported AI assistant types."""
    CLAUDE = "claude"
    GEMINI = "gemini"
    OPENCODE = "opencode"
    WINDSURF = "windsurf"
    CURSOR = "cursor"
    AUTO = "auto"


@dataclass
class MCPServer:
    """Represents an MCP server configuration."""
    name: str
    command: str
    args: List[str] = field(default_factory=list)
    env: Dict[str, str] = field(default_factory=dict)
    server_type: str = "stdio"  # stdio, http, sse
    
    def get_binaries(self) -> Set[str]:
        """Extract all binaries referenced in this MCP server."""
        # Handle both string and list commands
        if isinstance(self.command, list):
            binaries = {self.command[0]} if self.command else set()
        else:
            binaries = {self.command}
        
        # Check for common patterns in args
        for arg in self.args:
            # Check for uvx/npx package execution patterns
            if self.command in ["uvx", "npx"] and not arg.startswith("-"):
                # These are package names, not binaries
                continue
            # Check for direct binary references
            if "/" in arg and Path(arg).exists():
                binaries.add(arg)
                
        return binaries


@dataclass
class AssistantConfig:
    """Configuration for an AI assistant."""
    name: str
    type: AssistantType
    config_paths: List[Path]
    mcp_servers: Dict[str, MCPServer] = field(default_factory=dict)
    required_binaries: Set[str] = field(default_factory=set)
    required_paths: Set[str] = field(default_factory=set)


class AARG:
    """Main application for generating firejail Agentenanstaltsregeln for AI assistants."""
    
    def __init__(self, assistant_type: AssistantType = AssistantType.AUTO, 
                 verbose: bool = False):
        """Initialize the Agentenanstaltsregeln generator.

        Args:
            assistant_type: Type of AI assistant to configure institutional rules for
            verbose: Enable verbose logging
        """
        self.assistant_type = assistant_type
        self.verbose = verbose
        self.home_dir = Path.home()
        self.current_dir = Path.cwd()
        self.project_name = self.current_dir.name
        
        # Configure logging level
        if verbose:
            logger.setLevel(logging.DEBUG)
            
        # Collections for institutional rule generation
        self.whitelisted_paths: Set[str] = set()
        self.whitelisted_binaries: Set[str] = set()
        self.detected_assistants: List[AssistantConfig] = []
        
        # AI assistant binaries to always include
        self.ai_assistant_tools = [
            'claude', 'gemini', 'opencode', 'windsurf', 'cursor',
            'copilot', 'codeium', 'tabby', 'aider', 'continue'
        ]

        # Common development tools to always include
        self.common_tools = [
            # Package managers and runtimes
            'node', 'npm', 'npx', 'yarn', 'pnpm', 'bun', 'deno',
            'python', 'python3', 'pip', 'pip3', 'pipx',
            'uv', 'uvx', 'poetry', 'pdm', 'hatch', 'rye',
            'ruby', 'gem', 'bundler',
            'cargo', 'rustc', 'go', 'java', 'javac', 'gradle', 'maven',

            # Version control and network tools
            'git', 'gh', 'gitlab', 'curl', 'wget', 'ssh', 'rsync',

            # System tools
            'bash', 'sh', 'zsh', 'fish', 'ps', 'ls', 'cat', 'grep',
            'sed', 'awk', 'find', 'which', 'env', 'make', 'cmake',

            # Container tools
            'docker', 'podman', 'docker-compose', 'kubectl',

            # Common MCP servers
            'basic-memory', 'mcp', 'mcp-server',
        ]
        
    def detect_all_assistants(self) -> List[AssistantType]:
        """Detect all available AI assistants."""
        logger.debug("🔍 Starting comprehensive AI assistant detection")

        detected = []

        # Check for assistant executables and configs
        checks = [
            (AssistantType.CLAUDE, "claude", [
                # User configs
                self.home_dir / ".claude.json",
                self.home_dir / ".claude" / "claude.json",
                self.home_dir / ".config" / "claude" / "config.json",
                # Project configs
                self.current_dir / ".claude" / "settings.json",
                self.current_dir / ".claude" / "settings.local.json",
                # Enterprise/System configs
                Path("/etc/claude-code/managed-settings.json"),
                Path("/Library/Application Support/ClaudeCode/managed-settings.json")
            ]),
            (AssistantType.GEMINI, "gemini", [
                # User configs
                self.home_dir / ".gemini" / "settings.json",
                self.home_dir / ".config" / "gemini" / "config.json",
                # Project configs
                self.current_dir / ".gemini" / "settings.json",
                self.current_dir / ".gemini" / "config.json"
            ]),
            (AssistantType.OPENCODE, "opencode", [
                # Custom config via environment variable
                Path(os.environ.get("OPENCODE_CONFIG", "")),
                # Project configs (highest precedence)
                self.current_dir / "opencode.json",
                # User configs
                self.home_dir / ".config" / "opencode" / "opencode.json",
                self.home_dir / ".opencode.json"
            ]),
            (AssistantType.WINDSURF, "windsurf", [
                # User configs
                self.home_dir / ".windsurf" / "config.json",
                self.home_dir / ".config" / "windsurf" / "settings.json",
                self.home_dir / ".codeium" / ".codeiumignore",
                # Project configs
                self.current_dir / ".windsurfrules",
                self.current_dir / ".windsurf" / "rules"
            ]),
            (AssistantType.CURSOR, "cursor", [
                # User configs
                self.home_dir / ".cursor" / "config.json",
                self.home_dir / ".cursor" / "cli-config.json",
                self.home_dir / ".cursor-server",
                self.home_dir / ".config" / "cursor" / "settings.json",
                # Project configs
                self.current_dir / ".cursor" / "index.mdc"
            ])
        ]

        for assistant_type, executable, config_paths in checks:
            logger.debug(f"🔍 Checking for {assistant_type.value} ({executable})")

            found = False

            # Check if executable exists
            if shutil.which(executable):
                logger.debug(f"  ✅ Found executable: {executable}")
                found = True

            # Check if any config files exist
            for config_path in config_paths:
                # Skip empty paths (e.g., from empty environment variables)
                if str(config_path) and config_path.exists():
                    logger.debug(f"  ✅ Found config: {config_path}")
                    found = True
                    break

            if found:
                detected.append(assistant_type)

        if detected:
            logger.info(f"✅ Detected assistants: {[a.value for a in detected]}")
        else:
            logger.warning("⚠️  No AI assistants detected")

        return detected

    def detect_assistant_type(self) -> AssistantType:
        """Auto-detect primary AI assistant (for backward compatibility)."""
        detected = self.detect_all_assistants()
        return detected[0] if detected else AssistantType.AUTO

    def choose_assistant_interactive(self, detected: List[AssistantType]) -> AssistantType:
        """Allow user to choose from detected assistants."""
        if len(detected) == 1:
            return detected[0]

        logger.info(f"\n🤖 Multiple AI assistants detected:")
        for i, assistant in enumerate(detected, 1):
            logger.info(f"  {i}. {assistant.value}")
        logger.info(f"  {len(detected) + 1}. all (generate comprehensive profile)")

        while True:
            try:
                choice = input(f"\nChoose assistant (1-{len(detected) + 1}): ").strip()
                choice_num = int(choice)

                if 1 <= choice_num <= len(detected):
                    return detected[choice_num - 1]
                elif choice_num == len(detected) + 1:
                    return AssistantType.AUTO  # Will process all detected
                else:
                    logger.warning(f"Invalid choice. Please enter 1-{len(detected) + 1}")
            except KeyboardInterrupt:
                logger.info("\n\n🚪 Operation cancelled by user")
                exit(0)
            except (ValueError, EOFError):
                logger.warning(f"Invalid input. Please enter a number 1-{len(detected) + 1}")
                # For non-interactive environments, default to first detected
                return detected[0]
        
    def find_ai_assistant_configs(self) -> List[AssistantConfig]:
        """Find and parse all AI assistant configuration files."""
        configs = []

        # Handle assistant detection and selection
        if self.assistant_type == AssistantType.AUTO:
            detected = self.detect_all_assistants()
            if not detected:
                logger.warning("⚠️  No AI assistants detected, using generic configuration")
                return configs

            # For auto mode, offer interactive choice if multiple detected
            if len(detected) > 1:
                self.assistant_type = self.choose_assistant_interactive(detected)
                if self.assistant_type == AssistantType.AUTO:
                    # User chose "all" - process all detected assistants
                    target_assistants = detected
                else:
                    target_assistants = [self.assistant_type]
            else:
                self.assistant_type = detected[0]
                target_assistants = [self.assistant_type]
                logger.info(f"✅ Auto-detected assistant: {self.assistant_type.value}")
        else:
            # Specific assistant requested
            target_assistants = [self.assistant_type]

        # Define configuration paths for each assistant
        assistant_configs = {
            AssistantType.CLAUDE: [
                # User configs
                self.home_dir / ".claude.json",
                self.home_dir / ".claude" / "claude.json",
                self.home_dir / ".config" / "claude" / "config.json",
                # Project configs
                self.current_dir / ".claude" / "settings.json",
                self.current_dir / ".claude" / "settings.local.json",
                # Enterprise/System configs
                Path("/etc/claude-code/managed-settings.json"),
                Path("/Library/Application Support/ClaudeCode/managed-settings.json")
            ],
            AssistantType.GEMINI: [
                # User configs
                self.home_dir / ".gemini" / "settings.json",
                self.home_dir / ".config" / "gemini" / "config.json",
                # Project configs
                self.current_dir / ".gemini" / "settings.json",
                self.current_dir / ".gemini" / "config.json"
            ],
            AssistantType.OPENCODE: [
                # Custom config via environment variable
                Path(os.environ.get("OPENCODE_CONFIG", "")),
                # Project configs (highest precedence)
                self.current_dir / "opencode.json",
                # User configs
                self.home_dir / ".config" / "opencode" / "opencode.json",
                self.home_dir / ".opencode.json"
            ],
            AssistantType.WINDSURF: [
                # User configs
                self.home_dir / ".windsurf" / "config.json",
                self.home_dir / ".config" / "windsurf" / "settings.json",
                self.home_dir / ".codeium" / ".codeiumignore",
                # Project configs
                self.current_dir / ".windsurfrules",
                self.current_dir / ".windsurf" / "rules"
            ],
            AssistantType.CURSOR: [
                # User configs
                self.home_dir / ".cursor" / "config.json",
                self.home_dir / ".cursor" / "cli-config.json",
                self.home_dir / ".cursor-server",
                self.home_dir / ".config" / "cursor" / "settings.json",
                # Project configs
                self.current_dir / ".cursor" / "index.mdc"
            ]
        }

        # Process configs for target assistants
        for assistant_type in target_assistants:
            paths = assistant_configs.get(assistant_type, [])
            config = self._load_assistant_config(assistant_type, paths)
            if config:
                configs.append(config)

        return configs
        
    def _load_assistant_config(self, assistant_type: AssistantType,
                               paths: List[Path]) -> Optional[AssistantConfig]:
        """Load configuration for a specific assistant type."""
        config = AssistantConfig(
            name=assistant_type.value,
            type=assistant_type,
            config_paths=[]
        )

        found_config = False
        for path in paths:
            # Skip empty paths (e.g., from empty environment variables)
            if str(path) and path.exists():
                logger.debug(f"🔍 Found config file: {path}")
                config.config_paths.append(path)

                try:
                    with open(path, 'r') as f:
                        data = json.load(f)

                    logger.debug(f"✅ Successfully parsed config: {len(data)} top-level keys")

                    # Handle special Claude structure with project-specific sections
                    if assistant_type == AssistantType.CLAUDE and "projects" in data:
                        # Check global (user-level) MCP servers
                        if "mcpServers" in data:
                            logger.debug("🔍 Processing user-level Claude MCP servers")
                            mcp_servers = self.extract_mcp_servers(data, assistant_type)
                            config.mcp_servers.update(mcp_servers)

                        # Check project-specific MCP servers
                        projects = data.get("projects", {})
                        current_project_key = str(self.current_dir)
                        if current_project_key in projects:
                            project_data = projects[current_project_key]
                            logger.debug(f"🔍 Processing project-level Claude MCP servers for {current_project_key}")
                            project_mcp_servers = self.extract_mcp_servers(project_data, assistant_type)
                            config.mcp_servers.update(project_mcp_servers)

                            # Project-level configs take precedence
                            if project_mcp_servers and "mcpServers" in data:
                                logger.debug("📝 Project-level MCP servers take precedence over user-level")
                    else:
                        # Standard config format for other assistants
                        mcp_servers = self.extract_mcp_servers(data, assistant_type)
                        config.mcp_servers.update(mcp_servers)

                    # Extract other tool references
                    self._extract_tool_references(data, config)

                    found_config = True

                except (json.JSONDecodeError, IOError) as e:
                    logger.warning(f"⚠️  Error parsing {path}: {e}")

        # Check for potential secrets in config files
        if found_config:
            self._check_config_secrets(config)

        return config if found_config else None

    def _check_config_secrets(self, config: AssistantConfig) -> None:
        """Check configuration files for potential secrets and warn user."""
        secret_patterns = [
            'apiKey', 'api_key', 'token', 'secret', 'password', 'credentials',
            'auth', 'bearer', 'oauth', 'key', 'private'
        ]

        for config_path in config.config_paths:
            try:
                with open(config_path, 'r') as f:
                    content = f.read().lower()

                found_secrets = [pattern for pattern in secret_patterns if pattern.lower() in content]
                if found_secrets:
                    logger.warning(f"🔒 SECURITY WARNING: {config_path} may contain secrets ({', '.join(found_secrets)})")
                    logger.warning(f"    Consider using environment variables instead of storing secrets in config files")
                    logger.warning(f"    The firejail profile will grant access to this file")

            except IOError:
                pass  # File already processed, ignore read errors
        
    def extract_mcp_servers(self, config_data: Dict[str, Any], 
                           assistant_type: AssistantType) -> Dict[str, MCPServer]:
        """Extract MCP server configurations from config data."""
        mcp_servers = {}
        
        # Look for MCP servers in various locations
        if assistant_type == AssistantType.OPENCODE:
            # OpenCode uses "mcp" key with different structure
            mcp_data = config_data.get('mcp', {})
        else:
            # Claude, Gemini, and others use "mcpServers"
            mcp_data = (
                config_data.get('mcpServers', {}) or
                config_data.get('mcp_servers', {}) or
                config_data.get('servers', {}) or
                config_data.get('tools', {})
            )
        
        for server_name, server_config in mcp_data.items():
            if isinstance(server_config, dict):
                mcp_server = self._parse_mcp_server(server_name, server_config, assistant_type)
                if mcp_server:
                    mcp_servers[server_name] = mcp_server
                    logger.debug(f"✅ Added MCP server: {server_name} -> {mcp_server.command}")
                    
        return mcp_servers
        
    def _parse_mcp_server(self, name: str, config: Dict[str, Any], 
                         assistant_type: AssistantType) -> Optional[MCPServer]:
        """Parse a single MCP server configuration."""
        # Claude format: {"type": "stdio", "command": "...", "args": [...]}
        # Gemini format: {"command": "...", "args": [...]}
        # Generic format: {"executable": "...", "arguments": [...]}
        
        command = (
            config.get('command') or
            config.get('executable') or
            config.get('binary') or
            config.get('cmd')
        )

        if not command:
            return None

        # Handle command as either string or list
        if isinstance(command, list):
            # If command is a list, first element is the command, rest are args
            if not command:
                return None
            actual_command = command[0]
            command_args = command[1:] if len(command) > 1 else []
        else:
            # Command is a string
            actual_command = command
            command_args = []

        args = (
            config.get('args', []) or
            config.get('arguments', []) or
            config.get('params', [])
        )

        # Ensure args is a list and combine with command args
        if isinstance(args, str):
            args = args.split()
        elif not isinstance(args, list):
            args = []

        # Combine command args with explicit args
        final_args = command_args + args
            
        env = config.get('env', {}) or config.get('environment', {})
        server_type = config.get('type', 'stdio')
        
        return MCPServer(
            name=name,
            command=actual_command,
            args=final_args,
            env=env,
            server_type=server_type
        )
        
    def _extract_tool_references(self, data: Dict[str, Any], 
                                 config: AssistantConfig) -> None:
        """Extract additional tool references from configuration."""
        # Look for tool definitions in various formats
        tools_sections = [
            data.get('tools', {}),
            data.get('extensions', {}),
            data.get('plugins', {}),
            data.get('commands', {}),
        ]
        
        for section in tools_sections:
            if not isinstance(section, dict):
                continue
                
            for tool_name, tool_config in section.items():
                if isinstance(tool_config, dict):
                    # Extract command/binary references
                    for key in ['command', 'executable', 'binary', 'path']:
                        if key in tool_config:
                            binary = tool_config[key]
                            if isinstance(binary, str):
                                config.required_binaries.add(binary)
                                logger.debug(f"  Found tool reference: {binary}")
                                
                    # Extract path references
                    for key in ['workingDirectory', 'cwd', 'path', 'directory']:
                        if key in tool_config:
                            path = tool_config[key]
                            if isinstance(path, str):
                                config.required_paths.add(path)
                                
    def detect_cross_assistant_dependencies(self, configs: List[AssistantConfig]) -> Dict[str, Set[str]]:
        """Detect when MCP servers reference other AI assistants."""
        dependencies = {}

        for config in configs:
            config_deps = set()

            for server_name, mcp_server in config.mcp_servers.items():
                # Check if MCP command references another AI assistant
                for ai_tool in self.ai_assistant_tools:
                    if (mcp_server.command == ai_tool or
                        ai_tool in str(mcp_server.args) or
                        f"{ai_tool}-cli" in server_name.lower()):
                        config_deps.add(ai_tool)
                        logger.debug(f"🔗 {config.name} MCP '{server_name}' depends on '{ai_tool}'")

            if config_deps:
                dependencies[config.name] = config_deps

        return dependencies

    def resolve_dependency_configs(self, dependencies: Dict[str, Set[str]]) -> List[AssistantConfig]:
        """Load configurations for detected dependencies."""
        dependency_configs = []

        for primary_assistant, deps in dependencies.items():
            for dep_assistant in deps:
                # Convert string to AssistantType
                try:
                    dep_type = AssistantType(dep_assistant)
                except ValueError:
                    logger.debug(f"⚠️  Unknown assistant type: {dep_assistant}")
                    continue

                # Check if we already have this config loaded
                already_loaded = any(c.type == dep_type for c in dependency_configs)
                if already_loaded:
                    continue

                # Load dependency config
                assistant_configs = {
                    AssistantType.CLAUDE: [
                        # User configs
                        self.home_dir / ".claude.json",
                        self.home_dir / ".claude" / "claude.json",
                        self.home_dir / ".config" / "claude" / "config.json",
                        # Project configs
                        self.current_dir / ".claude" / "settings.json",
                        self.current_dir / ".claude" / "settings.local.json",
                        # Enterprise/System configs
                        Path("/etc/claude-code/managed-settings.json"),
                        Path("/Library/Application Support/ClaudeCode/managed-settings.json")
                    ],
                    AssistantType.GEMINI: [
                        # User configs
                        self.home_dir / ".gemini" / "settings.json",
                        self.home_dir / ".config" / "gemini" / "config.json",
                        # Project configs
                        self.current_dir / ".gemini" / "settings.json",
                        self.current_dir / ".gemini" / "config.json"
                    ],
                    AssistantType.OPENCODE: [
                        # Custom config via environment variable
                        Path(os.environ.get("OPENCODE_CONFIG", "")),
                        # Project configs (highest precedence)
                        self.current_dir / "opencode.json",
                        # User configs
                        self.home_dir / ".config" / "opencode" / "opencode.json",
                        self.home_dir / ".opencode.json"
                    ],
                    AssistantType.WINDSURF: [
                        # User configs
                        self.home_dir / ".windsurf" / "config.json",
                        self.home_dir / ".config" / "windsurf" / "settings.json",
                        self.home_dir / ".codeium" / ".codeiumignore",
                        # Project configs
                        self.current_dir / ".windsurfrules",
                        self.current_dir / ".windsurf" / "rules"
                    ],
                    AssistantType.CURSOR: [
                        # User configs
                        self.home_dir / ".cursor" / "config.json",
                        self.home_dir / ".cursor" / "cli-config.json",
                        self.home_dir / ".cursor-server",
                        self.home_dir / ".config" / "cursor" / "settings.json",
                        # Project configs
                        self.current_dir / ".cursor" / "index.mdc"
                    ]
                }

                paths = assistant_configs.get(dep_type, [])
                dep_config = self._load_assistant_config(dep_type, paths)
                if dep_config:
                    logger.info(f"🔗 Loaded dependency config for {dep_assistant} (used by {primary_assistant})")
                    dependency_configs.append(dep_config)

        return dependency_configs

    def collect_binaries(self, configs: List[AssistantConfig]) -> None:
        """Collect all required binaries and their paths."""
        all_binaries = set(self.common_tools)

        # Always include AI assistant binaries (for cross-assistant MCP dependencies)
        all_binaries.update(self.ai_assistant_tools)

        # Detect and resolve cross-assistant dependencies
        dependencies = self.detect_cross_assistant_dependencies(configs)
        if dependencies:
            logger.info(f"\n🔗 Detected cross-assistant dependencies: {dependencies}")

            # Ask user for confirmation (following Gemini's suggestion)
            for primary, deps in dependencies.items():
                deps_str = ", ".join(deps)
                try:
                    response = input(f"\n❓ {primary} uses {deps_str}. Include dependencies? [Y/n]: ").strip().lower()
                    if response in ['', 'y', 'yes']:
                        dependency_configs = self.resolve_dependency_configs({primary: deps})
                        configs.extend(dependency_configs)
                        logger.info(f"✅ Added {deps_str} dependencies")
                    else:
                        logger.info(f"⏭️  Skipped {deps_str} dependencies")
                except KeyboardInterrupt:
                    logger.info("\n\n🚪 Operation cancelled by user")
                    exit(0)
                except EOFError:
                    # Non-interactive environment, default to yes
                    dependency_configs = self.resolve_dependency_configs({primary: deps})
                    configs.extend(dependency_configs)
                    logger.info(f"✅ Auto-added {deps_str} dependencies (non-interactive mode)")

        # Add binaries from MCP servers
        for config in configs:
            for mcp_server in config.mcp_servers.values():
                all_binaries.update(mcp_server.get_binaries())
            all_binaries.update(config.required_binaries)
            
        logger.info("\n🔍 Searching for institutional tools (binaries)...")
        
        for binary in sorted(all_binaries):
            binary_path = self._find_binary_path(binary)
            if binary_path:
                self.whitelisted_binaries.add(binary_path)

                # Resolve symlinks and add target directories
                self._resolve_and_whitelist_symlinks(binary_path)

                logger.debug(f"  ✅ {binary}: {binary_path}")
            else:
                logger.debug(f"  ⚠️  {binary}: not found in PATH")
                
    def _find_binary_path(self, binary_name: str) -> Optional[str]:
        """Find the full path of a binary."""
        # First try which
        path = shutil.which(binary_name)
        if path:
            return path
            
        # Check common locations
        common_paths = [
            Path("/usr/local/bin") / binary_name,
            Path("/usr/bin") / binary_name,
            Path("/bin") / binary_name,
            self.home_dir / ".local" / "bin" / binary_name,
            self.home_dir / ".cargo" / "bin" / binary_name,
            self.home_dir / ".npm" / "bin" / binary_name,
            self.home_dir / ".yarn" / "bin" / binary_name,
        ]
        
        for path in common_paths:
            if path.exists() and path.is_file():
                return str(path)
                
        return None

    def _resolve_and_whitelist_symlinks(self, binary_path: str) -> None:
        """Resolve symlinks and add target directories to whitelist."""
        path = Path(binary_path)

        # If it's a symlink, resolve it and add target directory
        if path.is_symlink():
            try:
                target = path.readlink()

                # Handle relative symlinks
                if not target.is_absolute():
                    target = path.parent / target

                target = target.resolve()

                # Add the target's parent directory to whitelist
                # But avoid problematic system directories
                if target.exists():
                    target_dir = str(target.parent)
                    # Skip system directories that can't be whitelisted
                    if target_dir not in ['/usr/bin', '/bin', '/sbin', '/usr/sbin']:
                        self.whitelisted_paths.add(target_dir)
                        logger.debug(f"    ↳ Symlink target dir: {target_dir}")
                    else:
                        logger.debug(f"    ↳ Skipping system dir: {target_dir}")

                    # Recursively resolve if target is also a symlink
                    if target.is_symlink():
                        self._resolve_and_whitelist_symlinks(str(target))

            except (OSError, RuntimeError) as e:
                logger.debug(f"    ⚠️  Could not resolve symlink {binary_path}: {e}")

    def add_essential_paths(self, configs: List[AssistantConfig]) -> None:
        """Add essential directories for development tools and enterprise connectivity.

        Includes:
        - Dynamic system library discovery (no hardcoded versions)
        - Enterprise DNS resolution files (/etc/resolv.conf, /etc/hosts)
        - Assistant-specific config directories
        - Development tool paths
        """
        essential_paths = [
            # User directories
            str(self.home_dir / '.local'),
            str(self.home_dir / '.npm'),
            str(self.home_dir / '.yarn'),
            str(self.home_dir / '.pnpm'),
            str(self.home_dir / '.cache'),
            str(self.home_dir / '.config'),

            # Python environments
            str(self.home_dir / '.pyenv'),
            str(self.home_dir / '.virtualenvs'),
            str(self.home_dir / '.conda'),

            # Language-specific
            str(self.home_dir / '.cargo'),
            str(self.home_dir / '.rustup'),
            str(self.home_dir / '.gem'),
            str(self.home_dir / '.go'),

            # Development tools (only safe paths)
            '/etc/ssl/certs',  # For HTTPS connections

            # DNS resolution (essential for network connectivity)
            '/etc/resolv.conf',  # DNS server configuration
            '/etc/hosts',        # Local hostname resolution
            '/etc/nsswitch.conf', # Name service configuration
        ]

        # Essential system libraries - find actual paths dynamically
        system_libs = []

        # Dynamic linker (essential for all executables)
        for linker_path in ['/usr/lib64/ld-linux-x86-64.so.2', '/lib64/ld-linux-x86-64.so.2']:
            if os.path.exists(linker_path):
                system_libs.append(linker_path)
                break

        # Essential shared libraries - use glob to find versions
        import glob
        lib_patterns = [
            '/usr/lib64/libc.so.*',      # Core C library
            '/usr/lib64/libpthread.so.*', # POSIX threads
            '/usr/lib64/libm.so.*',      # Math library
            '/usr/lib64/libdl.so.*',     # Dynamic loading
            '/usr/lib64/libstdc++.so.*', # C++ runtime
            '/usr/lib64/libgcc_s.so.*'   # GCC runtime
        ]

        for pattern in lib_patterns:
            matches = glob.glob(pattern)
            if matches:
                # Add the first match (usually the main symlink)
                system_libs.append(sorted(matches)[0])

        # Add assistant-specific directories for ALL configs (including dependencies)
        assistant_paths_map = {
            AssistantType.CLAUDE: [
                str(self.home_dir / '.claude'),
                str(self.home_dir / '.config' / 'claude'),
                '/etc/claude-code',
                '/Library/Application Support/ClaudeCode'
            ],
            AssistantType.GEMINI: [
                str(self.home_dir / '.gemini'),
                str(self.home_dir / '.config' / 'gemini'),
            ],
            AssistantType.OPENCODE: [
                str(self.home_dir / '.config' / 'opencode'),
                str(self.home_dir / '.opencode'),
            ],
            AssistantType.WINDSURF: [
                str(self.home_dir / '.windsurf'),
                str(self.home_dir / '.config' / 'windsurf'),
                str(self.home_dir / '.codeium'),
            ],
            AssistantType.CURSOR: [
                str(self.home_dir / '.cursor'),
                str(self.home_dir / '.cursor-server'),
                str(self.home_dir / '.config' / 'cursor'),
            ]
        }

        # Add system libraries to essential paths
        essential_paths.extend(system_libs)

        for config in configs:
            paths_for_assistant = assistant_paths_map.get(config.type, [])
            essential_paths.extend(paths_for_assistant)

            # Add paths from config
            for path in config.required_paths:
                if path.startswith('~'):
                    path = str(self.home_dir / path[2:])
                essential_paths.append(path)
                
        logger.info("\n🏢 Adding permitted areas (directories) to institutional rules...")
        
        for path in essential_paths:
            # Skip system library directories that will be handled as read-only
            if path in ['/usr/lib64', '/usr/lib', '/lib64', '/lib']:
                logger.debug(f"  ⚠️  {path}: system library directory (handled as read-only)")
                continue

            if os.path.exists(path):
                self.whitelisted_paths.add(path)
                logger.debug(f"  ✅ {path}")
            else:
                logger.debug(f"  ⚠️  {path}: doesn't exist (skipping)")
                
    def generate_profile(self, enable_logging: bool = False, configs: List[AssistantConfig] = None) -> str:
        """Generate enterprise-ready firejail Agentenanstaltsregeln profile.

        Creates a whitelist-only security profile with:
        - Dynamic system library discovery (distribution-agnostic)
        - Enterprise DNS support (respects corporate DNS servers)
        - Proper network connectivity without restrictive netfilter
        - Cross-assistant dependency support (e.g., Claude + Gemini MCP)
        - Optional usage tracking for optimization
        """
        configs = configs or []

        # Generate profile name based on assistants included
        assistant_names = [config.name for config in configs] if configs else [self.assistant_type.value]
        if len(assistant_names) > 1:
            primary = assistant_names[0]
            dependencies = assistant_names[1:]
            profile_title = f"{primary.title()} with {', '.join(dep.title() for dep in dependencies)}"
        else:
            profile_title = assistant_names[0].title()

        profile_lines = [
            f"# aarg - Agentenanstaltsregeln for {profile_title}",
            f"# Project: {self.project_name}",
            f"# Generated institutional rules with permitted areas (directories) and tools (binaries)",
            "",
            "include globals.local",
            "",
            "# Working directory access - no private isolation (for compatibility)",
            f"# Restricting access via whitelist rules below instead of private directive",
            "",
        ]
        
        if enable_logging:
            profile_lines.extend([
                "# Logging and monitoring - track which areas are actually visited",
                "tracelog",
                "",
            ])
            
        profile_lines.extend([
            "# Permitted areas (whitelisted directories)",
        ])
        
        # Add whitelisted paths
        for path in sorted(self.whitelisted_paths):
            profile_lines.append(f"whitelist {path}")

        # Add essential system directories as read-only
        profile_lines.extend([
            "",
            "# Essential system libraries (read-only)",
            "read-only /usr/lib64",
            "read-only /usr/lib",
            "",
            "# Dynamic linker (essential for all executables)",
            "whitelist /usr/lib64/ld-linux-x86-64.so.2",
            "",
            "# Permitted tools (whitelisted binaries)",
        ])

        # Add whitelisted binaries
        for binary in sorted(self.whitelisted_binaries):
            profile_lines.append(f"whitelist {binary}")
            
        # Special handling for Docker/Podman
        if any('docker' in b or 'podman' in b for b in self.whitelisted_binaries):
            profile_lines.extend([
                "",
                "# Container tool access (Docker/Podman)",
                "ignore noroot",  # Docker needs root in container
                "whitelist /var/run/docker.sock",
                f"whitelist /run/user/{os.getuid()}/podman",
            ])
            
        profile_lines.extend([
            "",
            "# Network access (required for MCP servers and package managers)",
            "# Note: using system DNS to support enterprise/internal resources",
            "protocol unix,inet,inet6",
            "",
            "# Security restrictions - institutional rules",
            "noroot",
            "novideo",
            "nogroups",
            "nonewprivs",
            "",
            "# Disable unnecessary features - remove unused institutional amenities",
            "nodvd",
            "notv",
            "nou2f",
            "",
            "# Additional hardening",
            "caps.drop all",
            "seccomp",
            "private-dev"
        ])
        
        return "\n".join(profile_lines)
        
    def suggest_profile_path(self, configs: List[AssistantConfig] = None) -> Path:
        """Suggest a profile file path based on project and assistant(s)."""
        firejail_dir = self.home_dir / '.config' / 'firejail'
        firejail_dir.mkdir(parents=True, exist_ok=True)

        configs = configs or []

        # Generate filename based on assistants included
        if configs:
            assistant_names = [config.name for config in configs]
            if len(assistant_names) > 1:
                primary = assistant_names[0]
                dependencies = assistant_names[1:]
                profile_name = f"{primary}-with-{'-'.join(dependencies)}-{self.project_name}.profile"
            else:
                profile_name = f"{assistant_names[0]}-{self.project_name}.profile"
        else:
            assistant_name = self.assistant_type.value
            if assistant_name == "auto":
                assistant_name = "ai-assistant"
            profile_name = f"{assistant_name}-{self.project_name}.profile"

        return firejail_dir / profile_name
        
    def analyze_firejail_logs(self, log_file: Optional[Path] = None) -> Dict[str, Any]:
        """Analyze firejail trace logs to understand actual usage patterns."""
        if not log_file:
            # Look for most recent firejail log
            log_files = list(Path("/tmp").glob("firejail-*.log"))
            if not log_files:
                logger.error("❌ No firejail log files found in /tmp")
                return {}
                
            log_file = max(log_files, key=lambda p: p.stat().st_mtime)
            logger.info(f"📊 Analyzing most recent log: {log_file}")
            
        accessed_paths = set()
        access_patterns = {}
        
        try:
            with open(log_file, 'r') as f:
                for line in f:
                    # Parse firejail trace log format
                    if 'open(' in line or 'access(' in line:
                        # Extract path from syscall
                        match = re.search(r'"([^"]+)"', line)
                        if match:
                            path = match.group(1)
                            accessed_paths.add(path)
                            
                            # Track access patterns
                            path_type = self._categorize_path(path)
                            access_patterns[path_type] = access_patterns.get(path_type, 0) + 1
                            
        except IOError as e:
            logger.error(f"❌ Error reading log file: {e}")
            return {}
            
        # Save accessed paths for optimization
        accessed_file = self.current_dir / "accessed_paths.txt"
        with open(accessed_file, 'w') as f:
            for path in sorted(accessed_paths):
                f.write(f"{path}\n")
                
        logger.info(f"📊 Analysis complete:")
        logger.info(f"   Total rooms visited: {len(accessed_paths)}")
        logger.info(f"   Most frequently visited room types:")
        for path_type, count in sorted(access_patterns.items(), 
                                      key=lambda x: x[1], reverse=True)[:5]:
            logger.info(f"     - {path_type}: {count} visits")
        logger.info(f"   Complete access log saved to: {accessed_file}")
        
        return {
            'accessed_paths': accessed_paths,
            'access_patterns': access_patterns,
            'log_file': str(log_file)
        }
        
    def _categorize_path(self, path: str) -> str:
        """Categorize a path for analysis."""
        if path.startswith('/tmp'):
            return 'temporary'
        elif path.startswith('/usr/lib') or path.startswith('/lib'):
            return 'library'
        elif path.startswith('/usr/bin') or path.startswith('/bin'):
            return 'binary'
        elif path.startswith(str(self.home_dir)):
            if '/.cache' in path:
                return 'cache'
            elif '/.config' in path:
                return 'config'
            elif '/.local' in path:
                return 'local'
            else:
                return 'home'
        elif path.startswith('/etc'):
            return 'system_config'
        else:
            return 'other'
            
    def generate_optimized_profile(self, accessed_paths: Set[str]) -> str:
        """Generate an optimized profile based on actual usage."""
        # Determine which whitelisted items were actually used
        used_paths = set()
        used_binaries = set()
        unused_paths = set()
        unused_binaries = set()
        
        for path in self.whitelisted_paths:
            if any(accessed.startswith(path) for accessed in accessed_paths):
                used_paths.add(path)
            else:
                unused_paths.add(path)
                
        for binary in self.whitelisted_binaries:
            if binary in accessed_paths:
                used_binaries.add(binary)
            else:
                unused_binaries.add(binary)
                
        # Find accessed paths not in whitelist
        missing_paths = set()
        for accessed in accessed_paths:
            if not any(accessed.startswith(w) for w in self.whitelisted_paths):
                # Only suggest parent directories, not individual files
                parent = Path(accessed).parent
                if parent.exists() and parent.is_dir():
                    missing_paths.add(str(parent))
                    
        logger.info("\n📈 JAIL PLAN OPTIMIZATION ANALYSIS:")
        logger.info(f"   Rooms in jail plan: {len(self.whitelisted_paths)}")
        logger.info(f"   ✅ Used rooms: {len(used_paths)}")
        logger.info(f"   ❌ Unused rooms: {len(unused_paths)}")
        logger.info(f"   ⚠️  Missing rooms: {len(missing_paths)}")
        
        if unused_paths:
            logger.info("\n🗑️  UNUSED ROOMS (can be removed):")
            for path in sorted(unused_paths)[:10]:
                logger.info(f"   {path}")
                
        if missing_paths:
            logger.info("\n➕ SUGGESTED ROOM ADDITIONS:")
            for path in sorted(missing_paths)[:10]:
                logger.info(f"   whitelist {path}")
                
        # Generate optimized profile
        profile_lines = []
        for line in self.generate_profile(enable_logging=True).split('\n'):
            if line.startswith('whitelist '):
                path = line.replace('whitelist ', '')
                if path in unused_paths or path in unused_binaries:
                    profile_lines.append(f"# UNUSED ROOM: {line}")
                else:
                    profile_lines.append(line)
            else:
                profile_lines.append(line)
                
        # Add suggested additions
        if missing_paths:
            profile_lines.append("")
            profile_lines.append("# SUGGESTED ROOM ADDITIONS:")
            for path in sorted(missing_paths)[:10]:
                profile_lines.append(f"# whitelist {path}")
                
        return "\n".join(profile_lines)
        
    def run_generate_mode(self) -> None:
        """Main execution mode for generating Agentenanstaltsregeln."""
        logger.info("🎯 aarg - Agentenanstaltsregelgenerator")
        logger.info(f"🏗️  Project area: {self.project_name}")
        logger.info(f"🏛️  Institution location: {self.home_dir}")
        logger.info("")
        
        # Find and parse configurations
        configs = self.find_ai_assistant_configs()
        if not configs:
            logger.warning("⚠️  No AI assistant configurations found")
            logger.info("📝 Generating generic institutional rules with common tools only")
            configs = []  # Continue with empty configs
            
        # Show detected configurations
        for config in configs:
            logger.info(f"📋 Found {config.name} configuration:")
            logger.info(f"   Config files: {len(config.config_paths)}")
            logger.info(f"   MCP servers: {len(config.mcp_servers)}")
            if self.verbose and config.mcp_servers:
                for server_name, server in config.mcp_servers.items():
                    logger.info(f"     - {server_name}: {server.command}")
                    
        # Collect binaries and paths
        self.collect_binaries(configs)
        self.add_essential_paths(configs)
        
        # Ask about logging
        try:
            logging_response = input("\n❓ Enable access tracking (logging)? [y/N]: ").strip().lower()
            enable_logging = logging_response in ['y', 'yes']
        except KeyboardInterrupt:
            logger.info("\n\n🚪 Operation cancelled by user")
            exit(0)
        
        # Generate profile
        profile_content = self.generate_profile(enable_logging, configs)
        
        # Display generated profile
        logger.info("\n" + "="*60)
        logger.info("📄 GENERATED INSTITUTIONAL RULES:")
        logger.info("="*60)
        print(profile_content)
        logger.info("="*60)
        
        # Suggest save location
        suggested_path = self.suggest_profile_path(configs)
        logger.info(f"\n💾 Suggested institutional rules location:")
        logger.info(f"   {suggested_path}")

        # Ask to save
        try:
            response = input(f"\n❓ Save institutional rules to {suggested_path}? [y/N]: ").strip().lower()
        except KeyboardInterrupt:
            logger.info("\n\n🚪 Operation cancelled by user")
            exit(0)

        if response in ['y', 'yes']:
            try:
                with open(suggested_path, 'w') as f:
                    f.write(profile_content)
                logger.info(f"✅ Institutional rules saved to {suggested_path}")

                # Show usage instructions
                profile_name = suggested_path.stem
                assistant_cmd = configs[0].name if configs else self.assistant_type.value
                if assistant_cmd == "auto":
                    assistant_cmd = "claude code"  # Default example
                    
                logger.info(f"\n🎯 Lock up your app with:")
                if enable_logging:
                    logger.info(f"   # First run with tracking to capture usage:")
                    logger.info(f"   firejail --tracelog --profile={profile_name} {assistant_cmd}")
                    logger.info(f"   # Then optimize the floor plan:")
                    logger.info(f"   {sys.argv[0]} --optimize --assistant {self.assistant_type.value}")
                else:
                    logger.info(f"   firejail --profile={profile_name} {assistant_cmd}")

            except IOError as e:
                logger.error(f"❌ Error saving institutional rules: {e}")
        else:
            logger.info("📋 Institutional rules not saved. Copy the content above to use manually.")

        logger.info(f"\n🔒 These institutional rules restrict {self.assistant_type.value} to:")
        logger.info(f"   • Project area: {self.current_dir}")
        logger.info(f"   • {len(self.whitelisted_paths)} permitted areas")
        logger.info(f"   • {len(self.whitelisted_binaries)} permitted tools")
        
    def run_analysis_mode(self) -> None:
        """Run analysis mode to examine firejail logs."""
        logger.info("📊 FIREJAIL LOG ANALYSIS MODE")
        logger.info("")
        
        analysis = self.analyze_firejail_logs()
        if not analysis:
            logger.error("❌ Analysis failed - no logs found")
            return
            
        # Additional analysis could be added here
        logger.info("\n💡 Next step: Run optimization mode to clean up your jail plan")
        logger.info(f"   {sys.argv[0]} --optimize --assistant {self.assistant_type.value}")
        
    def run_optimization_mode(self) -> None:
        """Run optimization mode to refine existing profiles."""
        logger.info("🔧 JAIL PLAN OPTIMIZATION MODE")
        logger.info("")
        
        # First analyze logs
        analysis = self.analyze_firejail_logs()
        if not analysis:
            logger.error("❌ Cannot optimize without usage data")
            logger.info("💡 First run your AI assistant with logging enabled:")
            logger.info("   firejail --tracelog --profile=your-profile assistant-command")
            return
            
        # Regenerate profile configuration
        configs = self.find_ai_assistant_configs()
        self.collect_binaries(configs)
        self.add_essential_paths(configs)
        
        # Generate optimized profile
        optimized_profile = self.generate_optimized_profile(
            analysis['accessed_paths']
        )
        
        # Save optimized profile
        original_path = self.suggest_profile_path()
        optimized_path = original_path.with_suffix('.optimized.profile')
        
        try:
            response = input(f"\n❓ Save optimized institutional rules to {optimized_path}? [y/N]: ").strip().lower()
        except KeyboardInterrupt:
            logger.info("\n\n🚪 Operation cancelled by user")
            exit(0)

        if response in ['y', 'yes']:
            try:
                with open(optimized_path, 'w') as f:
                    f.write(optimized_profile)
                logger.info(f"✅ Optimized institutional rules saved to {optimized_path}")
                logger.info("\n💡 Test the optimized plan:")
                logger.info(f"   firejail --profile={optimized_path.stem} {self.assistant_type.value}")
                logger.info("\nIf it works well, replace the original:")
                logger.info(f"   mv {optimized_path} {original_path}")
            except IOError as e:
                logger.error(f"❌ Error saving optimized profile: {e}")


def main():
    """Main entry point for the application."""
    parser = argparse.ArgumentParser(
        description="aarg - Enterprise-ready Agentenanstaltsregelgenerator for AI Coding Assistants",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
Examples:
  %(prog)s                    # Auto-detect assistant and generate enterprise-ready rules
  %(prog)s --assistant claude # Generate rules for Claude Code with dynamic library discovery
  %(prog)s --analyze          # Analyze firejail logs to see usage patterns
  %(prog)s --optimize         # Optimize existing rules based on actual usage
  %(prog)s --verbose          # Show detailed debugging information

Features:
  • Dynamic system library discovery (no hardcoded versions)
  • Enterprise DNS support (respects corporate DNS servers)
  • Cross-assistant dependency detection (Claude + Gemini MCP)
  • Distribution-agnostic profiles (works on any Linux distro)
  • Whitelist-only security (principle of least privilege)
        """
    )
    
    parser.add_argument(
        "--assistant",
        type=str,
        choices=[t.value for t in AssistantType],
        default="auto",
        help="AI assistant type (default: auto-detect)"
    )
    
    parser.add_argument(
        "--analyze",
        action="store_true",
        help="Analyze firejail logs to understand usage patterns"
    )
    
    parser.add_argument(
        "--optimize",
        action="store_true",
        help="Optimize existing institutional rules based on usage logs"
    )
    
    parser.add_argument(
        "--verbose",
        action="store_true",
        help="Enable verbose debug output"
    )
    
    args = parser.parse_args()
    
    # Create application instance
    assistant_type = AssistantType(args.assistant)
    app = AARG(assistant_type=assistant_type, verbose=args.verbose)
    
    # Run appropriate mode
    if args.analyze:
        app.run_analysis_mode()
    elif args.optimize:
        app.run_optimization_mode()
    else:
        app.run_generate_mode()


if __name__ == "__main__":
    main()
